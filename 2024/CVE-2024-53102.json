{
	"id": "CVE-2024-53102",
	"sourceIdentifier": "416baaa9-dc9f-4396-8d5f-8c081fb06d67",
	"vulnStatus": "Received",
	"published": "2024-11-25T22:15:17.553",
	"lastModified": "2024-11-25T22:15:17.553",
	"descriptions": [
		{
			"lang": "en",
			"value": "In the Linux kernel, the following vulnerability has been resolved:\n\nnvme: make keep-alive synchronous operation\n\nThe nvme keep-alive operation, which executes at a periodic interval,\ncould potentially sneak in while shutting down a fabric controller.\nThis may lead to a race between the fabric controller admin queue\ndestroy code path (invoked while shutting down controller) and hw/hctx\nqueue dispatcher called from the nvme keep-alive async request queuing\noperation. This race could lead to the kernel crash shown below:\n\nCall Trace:\n    autoremove_wake_function+0x0/0xbc (unreliable)\n    __blk_mq_sched_dispatch_requests+0x114/0x24c\n    blk_mq_sched_dispatch_requests+0x44/0x84\n    blk_mq_run_hw_queue+0x140/0x220\n    nvme_keep_alive_work+0xc8/0x19c [nvme_core]\n    process_one_work+0x200/0x4e0\n    worker_thread+0x340/0x504\n    kthread+0x138/0x140\n    start_kernel_thread+0x14/0x18\n\nWhile shutting down fabric controller, if nvme keep-alive request sneaks\nin then it would be flushed off. The nvme_keep_alive_end_io function is\nthen invoked to handle the end of the keep-alive operation which\ndecrements the admin->q_usage_counter and assuming this is the last/only\nrequest in the admin queue then the admin->q_usage_counter becomes zero.\nIf that happens then blk-mq destroy queue operation (blk_mq_destroy_\nqueue()) which could be potentially running simultaneously on another\ncpu (as this is the controller shutdown code path) would forward\nprogress and deletes the admin queue. So, now from this point onward\nwe are not supposed to access the admin queue resources. However the\nissue here's that the nvme keep-alive thread running hw/hctx queue\ndispatch operation hasn't yet finished its work and so it could still\npotentially access the admin queue resource while the admin queue had\nbeen already deleted and that causes the above crash.\n\nThis fix helps avoid the observed crash by implementing keep-alive as a\nsynchronous operation so that we decrement admin->q_usage_counter only\nafter keep-alive command finished its execution and returns the command\nstatus back up to its caller (blk_execute_rq()). This would ensure that\nfabric shutdown code path doesn't destroy the fabric admin queue until\nkeep-alive request finished execution and also keep-alive thread is not\nrunning hw/hctx queue dispatch operation."
		},
		{
			"lang": "es",
			"value": "En el kernel de Linux, se ha resuelto la siguiente vulnerabilidad: nvme: operación sincrónica de mantenimiento de conexión La operación de mantenimiento de conexión de nvme, que se ejecuta a intervalos periódicos, podría colarse mientras se apaga un controlador de red. Esto puede generar una ejecución entre la ruta del código de destrucción de la cola de administración del controlador de red (invocada mientras se apaga el controlador) y el despachador de cola hw/hctx llamado desde la operación de puesta en cola de solicitudes asincrónicas de mantenimiento de conexión de nvme. Esta ejecución podría provocar el bloqueo del kernel que se muestra a continuación: Rastreo de llamada: autoremove_wake_function+0x0/0xbc (no confiable) __blk_mq_sched_dispatch_requests+0x114/0x24c blk_mq_sched_dispatch_requests+0x44/0x84 blk_mq_run_hw_queue+0x140/0x220 nvme_keep_alive_work+0xc8/0x19c [nvme_core] process_one_work+0x200/0x4e0 worker_thread+0x340/0x504 kthread+0x138/0x140 start_kernel_thread+0x14/0x18 Al apagar el controlador de estructura, si la solicitud de mantenimiento de conexión de nvme se cuela, se eliminará. Luego se invoca la función nvme_keep_alive_end_io para manejar el final de la operación keep-alive que disminuye el admin-&gt;q_usage_counter y, asumiendo que esta es la última/única solicitud en la cola de administración, entonces el admin-&gt;q_usage_counter se convierte en cero. Si eso sucede, entonces la operación de destrucción de cola blk-mq (blk_mq_destroy_queue()) que podría estar ejecutándose simultáneamente en otra CPU (ya que esta es la ruta del código de apagado del controlador) reenviaría el progreso y eliminaría la cola de administración. Entonces, ahora a partir de este punto en adelante no se supone que accedamos a los recursos de la cola de administración. Sin embargo, el problema aquí es que el hilo de keep-alive de nvme que ejecuta la operación de despacho de cola hw/hctx aún no ha terminado su trabajo y, por lo tanto, aún podría acceder potencialmente al recurso de la cola de administración mientras que la cola de administración ya se había eliminado y eso causa el bloqueo anterior. Esta corrección ayuda a evitar el bloqueo observado al implementar keep-alive como una operación sincrónica de modo que disminuyamos admin-&gt;q_usage_counter solo después de que el comando keep-alive finalice su ejecución y devuelva el estado del comando a su llamador (blk_execute_rq()). Esto garantizaría que la ruta del código de apagado de la estructura no destruya la cola de administración de la estructura hasta que la solicitud keep-alive finalice la ejecución y también que el subproceso keep-alive no esté ejecutando la operación de despacho de cola hw/hctx."
		}
	],
	"references": [
		{
			"source": "416baaa9-dc9f-4396-8d5f-8c081fb06d67",
			"url": "https://git.kernel.org/stable/c/1a1bcca5c9efd2c72c8d2fcbadf2d673cceb2ea7"
		},
		{
			"source": "416baaa9-dc9f-4396-8d5f-8c081fb06d67",
			"url": "https://git.kernel.org/stable/c/afa229465399f89d3af9d72ced865144c9748846"
		},
		{
			"source": "416baaa9-dc9f-4396-8d5f-8c081fb06d67",
			"url": "https://git.kernel.org/stable/c/ccc1d82dfaad0ad27d21139da22e57add73d2a5e"
		},
		{
			"source": "416baaa9-dc9f-4396-8d5f-8c081fb06d67",
			"url": "https://git.kernel.org/stable/c/d06923670b5a5f609603d4a9fee4dec02d38de9c"
		}
	],
	"metrics": {}
}
